# Vision-based Control of a Quadrotor in User Proximity: Mediated vs End-to-End Learning Approaches
*Dario Mantegazza, Jérôme Guzzi, Luca M. Gambardella and Alessandro Giusti*
## *Abstract*
We consider the task of controlling a quadrotor
to hover in front of a freely moving user, using input data
from an onboard camera. On this specific task we compare two
widespread learning paradigms: a mediated approach, which
learns an high-level state from the input and then uses it for de-
riving control signals; and an end-to-end approach, which skips
high-level state estimation altogether. We show that despite
their fundamental difference, both approaches yield equivalent
performance on this task. We finally qualitatively analyze the
behavior of a quadrotor implementing such approaches.
### Dataset
The Dataset used is composed of 21 different [rosbag](http://wiki.ros.org/rosbag) files. 
Each rosbag correspond to a single recording session. 
In each file we recorded multiple available [topics](http://wiki.ros.org/Topics)
[here](https://drive.switch.ch/index.php/s/1Q0zN0XDzyRxug4)


### Code
TODO [here](https://github.com/idsia-robotics/proximity-quadrotor-learning/tree/master/script)

### Video
TODO
[here](https://github.com/idsia-robotics/proximity-quadrotor-learning/tree/master/video)

### Errata
TODO
